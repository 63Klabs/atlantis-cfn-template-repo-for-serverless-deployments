version: 0.2

# Recommended Pipeline Template "templates/v2/pipeline/template-pipeline-build-only"
# Assumes HOST_BUCKET is already set in CodeBuild environment variables

env:
  variables:
    SOURCE_DIR: "templates"
    S3_HOST_BASE_PATH: "/atlantis/" # Must be single / or begin and end with / (suggested: /atlantis/)
    DRYRUN: "" # set to "--dryrun" if performing dry runs

phases:
  install:
    runtime-versions:
      nodejs: latest
      python: latest
    commands:
      - pip install --upgrade awscli boto3
      - echo "Setting up CFN template validation environment..."
      - python scripts/setup_venv.py
      - echo "CFN validation environment setup complete"
      - echo "Installing test requirements into virtual environment..."
      - .venv/bin/pip install -r tests/requirements.txt
      - echo "All dependencies installed"

  pre_build:
    commands:
      - echo $S3_STATIC_HOST_BUCKET$S3_HOST_BASE_PATH # S3_STATIC_HOST_BUCKET is set in CodeBuild environment variables
      - echo $DRYRUN

  build:
    commands:
      - echo "Build phase started at $(date)"
      - echo "Running CloudFormation template validation..."
      - .venv/bin/python scripts/cfn_lint_runner.py --templates-dir templates/v2 --verbose || CFN_VALIDATION_FAILED=1
      - echo "Running PostDeploy template tests..."
      - cd tests
      - echo "Running unit tests..."
      - ../.venv/bin/python -m pytest test_postdeploy_unit.py -v --tb=short --junit-xml=test-results-unit.xml || TEST_FAILED=1
      - echo "Running property-based tests..."
      - ../.venv/bin/python -m pytest test_postdeploy_property_based.py -v --tb=short --junit-xml=test-results-property.xml || TEST_FAILED=1
      - echo "Running CFN validation tests..."
      - ../.venv/bin/python -m pytest test_cfn_templates.py -v --tb=short --junit-xml=test-results-cfn.xml || TEST_FAILED=1
      - echo "Combining test results..."
      - |
        ../.venv/bin/python -c "
        import xml.etree.ElementTree as ET
        import os
        
        # Combine JUnit XML files
        combined = ET.Element('testsuites')
        
        for file in ['test-results-unit.xml', 'test-results-property.xml', 'test-results-cfn.xml']:
            if os.path.exists(file):
                tree = ET.parse(file)
                root = tree.getroot()
                if root.tag == 'testsuites':
                    for testsuite in root:
                        combined.append(testsuite)
                elif root.tag == 'testsuite':
                    combined.append(root)
        
        # Write combined results
        ET.ElementTree(combined).write('test-results.xml', encoding='utf-8', xml_declaration=True)
        print('Test results combined successfully')
        "
      - cd ..
      - if [ "$CFN_VALIDATION_FAILED" = "1" ]; then echo "CloudFormation template validation failed - check output for details" && exit 1; fi
      - if [ "$TEST_FAILED" = "1" ]; then echo "Some tests failed - check test reports for details" && exit 1; fi

  post_build:
    commands:
      - export S3_HOST_BASE_PATH_UTILITIES="${S3_HOST_BASE_PATH}utilities/v2/"
      - export S3_HOST_BASE_PATH_TEMPLATES="${S3_HOST_BASE_PATH}templates/"

      # Replace placeholder bucketname with template bucket name
      - echo "Replacing placeholder bucketname with actual bucket name in templates..."
      - python3 ./scripts/replace_bucket_name.py $SOURCE_DIR $S3_STATIC_HOST_BUCKET

      # We use versioning on the buckets so that we can specify a specific version of the template to use
      # Therefore, so we do not create extra versions, we will use only copy changed files.

      # Copy template files to host bucket
      - echo "Executing script to sync templates..."
      - ./scripts/sync_templates.sh $SOURCE_DIR $S3_STATIC_HOST_BUCKET $S3_HOST_BASE_PATH_TEMPLATES $DRYRUN
      # If you have additional directories you can sync them next as long as you have a unique local and unique remote directory (don't use same as previous otherwise it will perform a delete)
#      - ./scripts/sync_templates.sh custom-templates $S3_STATIC_HOST_BUCKET $S3_HOST_BASE_PATH/custom-templates $DRYRUN

      # Send sharable scripts to host bucket
      - echo "Executing script to upload scripts..."
      - ./scripts/upload_scripts.sh $S3_STATIC_HOST_BUCKET $S3_HOST_BASE_PATH_UTILITIES scripts $DRYRUN

artifacts:
  files:
    - '**/*'
  reports:
    postdeploy-tests:
      files:
        - 'tests/test-results.xml'
      file-format: 'JUNITXML'